{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "import networkx\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Speaker1: Now That I'm Older it's so obvious when someone is not interested in even talking to you but they clearly have some there going through the motions to talk to you in a second why would you waste our time. The second one is going through conversation wanting to have a conversation if you die if you don't have a conversation don't because the other person is going to know it very quickly and it's going to make them feel weird I think a lot of men may be in the younger side of the more immature try to have a conversation with a woman because they think this is the barrier to entry like oh okay I have to pretend like I want to talk to her and then we'll have sex what is transactional that way especially women they are much more tuned to the seller details of life than a man ever is\\nSpeaker1: General course people can tell if you have a motive you know obviously\\nSpeaker2: it's because then eventually have to get my question out that I really want to talk to you about the thing\\nwe talked about the past as well someone will always remember how you made them feel much more than anything you've\\never said so if you make someone feel comfortable or like clearly you're just using me to get to whatever ends you think that won't you usually won't get a second chance to make an impression on that person so you got it just don't\\nwant her conversation want to have a conversation be interesting to people so it has something to do with the first\\npoint but it's definitely little bit\\nSpeaker1: different thing be complementary I don't\\nSpeaker2: think you'll meet a single woman ever in your life who doesn't love a compliment but there's something to be said of a type of complement a delivery and the delivery and the Stella compliment is going to make or break time\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/Users/ramakrishnareddych/Downloads/results.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simce the nltk split the text into just 2 sentences, we're going with a custom text split \n",
    "sentences = text.split('\\n')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Speaker1: Now That I'm Older it's so obvious when someone is not interested in even talking to you but they clearly have some there going through the motions to talk to you in a second why would you waste our time. The second one is going through conversation wanting to have a conversation if you die if you don't have a conversation don't because the other person is going to know it very quickly and it's going to make them feel weird I think a lot of men may be in the younger side of the more immature try to have a conversation with a woman because they think this is the barrier to entry like oh okay I have to pretend like I want to talk to her and then we'll have sex what is transactional that way especially women they are much more tuned to the seller details of life than a man ever is\",\n",
       " 'Speaker1: General course people can tell if you have a motive you know obviously',\n",
       " \"Speaker2: it's because then eventually have to get my question out that I really want to talk to you about the thing\",\n",
       " \"we talked about the past as well someone will always remember how you made them feel much more than anything you've\",\n",
       " \"ever said so if you make someone feel comfortable or like clearly you're just using me to get to whatever ends you think that won't you usually won't get a second chance to make an impression on that person so you got it just don't\",\n",
       " 'want her conversation want to have a conversation be interesting to people so it has something to do with the first',\n",
       " \"point but it's definitely little bit\",\n",
       " \"Speaker1: different thing be complementary I don't\",\n",
       " \"Speaker2: think you'll meet a single woman ever in your life who doesn't love a compliment but there's something to be said of a type of complement a delivery and the delivery and the Stella compliment is going to make or break time\",\n",
       " '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_text = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_sentences = normalize_text(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barrier</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>break</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chance</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clearly</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfortable</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complement</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complementary</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1    2     3     4    5    6     7    8    9\n",
       "always         0.00  0.0  0.0  0.32  0.00  0.0  0.0  0.00  0.0  0.0\n",
       "anything       0.00  0.0  0.0  0.32  0.00  0.0  0.0  0.00  0.0  0.0\n",
       "barrier        0.11  0.0  0.0  0.00  0.00  0.0  0.0  0.00  0.0  0.0\n",
       "bit            0.00  0.0  0.0  0.00  0.00  0.0  0.5  0.00  0.0  0.0\n",
       "break          0.00  0.0  0.0  0.00  0.00  0.0  0.0  0.00  0.2  0.0\n",
       "chance         0.00  0.0  0.0  0.00  0.20  0.0  0.0  0.00  0.0  0.0\n",
       "clearly        0.09  0.0  0.0  0.00  0.17  0.0  0.0  0.00  0.0  0.0\n",
       "comfortable    0.00  0.0  0.0  0.00  0.20  0.0  0.0  0.00  0.0  0.0\n",
       "complement     0.00  0.0  0.0  0.00  0.00  0.0  0.0  0.00  0.2  0.0\n",
       "complementary  0.00  0.0  0.0  0.00  0.00  0.0  0.0  0.52  0.0  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "t_vector = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "dt_matrix = t_vector.fit_transform(normalize_sentences)\n",
    "dt_matrix = dt_matrix.toarray()\n",
    "\n",
    "vocab = t_vector.get_feature_names()\n",
    "td_matrix = dt_matrix.T\n",
    "print(td_matrix.shape)\n",
    "pd.DataFrame(np.round(td_matrix, 2), index=vocab).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL - 1 Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u, s, vt = svds(matrix, k=singular_count)\n",
    "    return u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 2) (2,) (2, 10)\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 6 # How many sentences we want our summary to be\n",
    "num_topics = 2 # since we have only two speakers\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "print(u.shape, s.shape, vt.shape)\n",
    "term_topic_mat, singular_values, topic_document_mat = u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing singular values below threshold                                         \n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(singular_values) * sv_threshold\n",
    "singular_values[singular_values < min_sigma_value] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.49810988e-01, 4.11306217e-01, 7.16819148e-01, 4.20653070e-01,\n",
       "       5.83409587e-01, 5.01181979e-01, 1.78791120e-16, 6.72847054e-01,\n",
       "       5.26884710e-01, 5.95290024e-16])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores = np.sqrt(np.dot(np.square(singular_values), np.square(topic_document_mat)))\n",
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentences = (sentence_scores).argsort()[:num_sentences]\n",
    "top_sentences.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1: General course people can tell if you have a motive you know obviously\n",
      "we talked about the past as well someone will always remember how you made them feel much more than anything you've\n",
      "want her conversation want to have a conversation be interesting to people so it has something to do with the first\n",
      "point but it's definitely little bit\n",
      "Speaker2: think you'll meet a single woman ever in your life who doesn't love a compliment but there's something to be said of a type of complement a delivery and the delivery and the Stella compliment is going to make or break time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary with the help of Latent Semantic analysis\n",
    "\n",
    "print('\\n'.join(np.array(sentences)[top_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL - 2 TEXT RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.05, 0.11, 0.09, 0.21, 0.26, 0.  , 0.09, 0.17, 0.  ],\n",
       "       [0.05, 1.  , 0.05, 0.  , 0.  , 0.09, 0.  , 0.07, 0.03, 0.  ],\n",
       "       [0.11, 0.05, 1.  , 0.  , 0.12, 0.15, 0.  , 0.23, 0.03, 0.  ],\n",
       "       [0.09, 0.  , 0.  , 1.  , 0.07, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.21, 0.  , 0.12, 0.07, 1.  , 0.  , 0.  , 0.06, 0.12, 0.  ],\n",
       "       [0.26, 0.09, 0.15, 0.  , 0.  , 1.  , 0.  , 0.  , 0.05, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ],\n",
       "       [0.09, 0.07, 0.23, 0.  , 0.06, 0.  , 0.  , 1.  , 0.04, 0.  ],\n",
       "       [0.17, 0.03, 0.03, 0.  , 0.12, 0.05, 0.  , 0.04, 1.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = np.matmul(dt_matrix, dt_matrix.T)\n",
    "print(similarity_matrix.shape)\n",
    "np.round(similarity_matrix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_graph = networkx.from_numpy_array(similarity_matrix)\n",
    "TR_Sentence_scores = networkx.pagerank(similarity_graph)\n",
    "sentences_rank = sorted(((score, index) for index, score in TR_Sentence_scores.items()), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_top_sentences = [sentences_rank[index][1] \n",
    "                        for index in range(num_sentences)]\n",
    "TR_top_sentences.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1: Now That I'm Older it's so obvious when someone is not interested in even talking to you but they clearly have some there going through the motions to talk to you in a second why would you waste our time. The second one is going through conversation wanting to have a conversation if you die if you don't have a conversation don't because the other person is going to know it very quickly and it's going to make them feel weird I think a lot of men may be in the younger side of the more immature try to have a conversation with a woman because they think this is the barrier to entry like oh okay I have to pretend like I want to talk to her and then we'll have sex what is transactional that way especially women they are much more tuned to the seller details of life than a man ever is\n",
      "Speaker2: it's because then eventually have to get my question out that I really want to talk to you about the thing\n",
      "ever said so if you make someone feel comfortable or like clearly you're just using me to get to whatever ends you think that won't you usually won't get a second chance to make an impression on that person so you got it just don't\n",
      "want her conversation want to have a conversation be interesting to people so it has something to do with the first\n",
      "point but it's definitely little bit\n",
      "Speaker1: different thing be complementary I don't\n"
     ]
    }
   ],
   "source": [
    "# Summary with the help of TEXT RANK\n",
    "\n",
    "print('\\n'.join(np.array(sentences)[TR_top_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL - 3 GENSIM SUMMARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1: Now That I'm Older it's so obvious when someone is not interested in even talking to you but they clearly have some there going through the motions to talk to you in a second why would you waste our time.\n",
      "The second one is going through conversation wanting to have a conversation if you die if you don't have a conversation don't because the other person is going to know it very quickly and it's going to make them feel weird I think a lot of men may be in the younger side of the more immature try to have a conversation with a woman because they think this is the barrier to entry like oh okay I have to pretend like I want to talk to her and then we'll have sex what is transactional that way especially women they are much more tuned to the seller details of life than a man ever is\n",
      "ever said so if you make someone feel comfortable or like clearly you're just using me to get to whatever ends you think that won't you usually won't get a second chance to make an impression on that person so you got it just don't\n",
      "Speaker2: think you'll meet a single woman ever in your life who doesn't love a compliment but there's something to be said of a type of complement a delivery and the delivery and the Stella compliment is going to make or break time\n"
     ]
    }
   ],
   "source": [
    "# adjust the ratio to see what percentage of text the summary should be \n",
    "\n",
    "print(summarize(text, ratio=0.4, split=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second one is going through conversation wanting to have a conversation if you die if you don't have a conversation don't because the other person is going to know it very quickly and it's going to make them feel weird I think a lot of men may be in the younger side of the more immature try to have a conversation with a woman because they think this is the barrier to entry like oh okay I have to pretend like I want to talk to her and then we'll have sex what is transactional that way especially women they are much more tuned to the seller details of life than a man ever is\n",
      "ever said so if you make someone feel comfortable or like clearly you're just using me to get to whatever ends you think that won't you usually won't get a second chance to make an impression on that person so you got it just don't\n"
     ]
    }
   ],
   "source": [
    "# we can even modify the word count from the Gensim Summarization\n",
    "\n",
    "print(summarize(text, word_count=150, split=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
